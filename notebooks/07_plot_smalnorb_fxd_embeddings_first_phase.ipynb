{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from model.network import Converter\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import lpips_tf\n",
    "\n",
    "from keras import backend as K\n",
    "from keras import optimizers, losses, regularizers\n",
    "from keras.layers import Conv2D, Dense, UpSampling2D, LeakyReLU, Activation\n",
    "from keras.layers import Layer, Input, Reshape, Lambda, Flatten, Concatenate, Embedding, GaussianNoise\n",
    "from keras.models import Model, load_model\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, Callback\n",
    "from keras.applications import vgg16\n",
    "from keras_lr_multiplier import LRMultiplier\n",
    "from keras.models import Sequential\n",
    "from assets import AssetManager\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\saving.py:341: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vgg arch:\n",
      "Model: \"vgg\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 64, 64, 1)         0         \n",
      "_________________________________________________________________\n",
      "lambda_2 (Lambda)            (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "vgg_normalization_2 (VggNorm (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "model_2 (Model)              [(None, 64, 64, 64), (Non 14714688  \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_name = 'smallnorb_model_first_phase'\n",
    "assets = AssetManager('results')\n",
    "converter = Converter.load( assets.get_model_dir(model_name), include_encoders=False)\n",
    "\n",
    "def pred_imgs(imgs):\n",
    "    curr_imgs = np.stack(imgs, axis=0)\n",
    "    content_codes = converter.content_encoder.predict(curr_imgs)\n",
    "    class_codes = converter.class_encoder.predict(curr_imgs)\n",
    "    class_adain_params = converter.class_modulation.predict(class_codes)\n",
    "    return content_codes, class_adain_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(assets.get_preprocess_file_path('smallnorb_strict_class_train'))\n",
    "imgs, classes, _, n_classes = data['imgs'], data['classes'], data['contents'], data['n_classes']\n",
    "imgs = imgs.astype(np.float32) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_content = converter.content_embedding.predict(np.arange(imgs.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_code = converter.class_embedding.predict(classes)\n",
    "class_adain_params = converter.class_modulation.predict(class_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, classes, train_content, class_code, class_adain_params = \\\n",
    "    shuffle(imgs, classes, train_content, class_code, class_adain_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((38880, 128), (38880, 4, 256, 2))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_code.shape, class_adain_params.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(input_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=256, activation='relu', input_dim=input_dim))\n",
    "    model.add(Dense(units=n_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_enc = OneHotEncoder()\n",
    "onehot_classes = onehot_enc.fit_transform(classes.reshape(-1,1))\n",
    "n_classes = onehot_classes.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27216 samples, validate on 11664 samples\n",
      "Epoch 1/200\n",
      "27216/27216 [==============================] - 3s 94us/step - loss: 3.7572 - accuracy: 0.0481 - val_loss: 3.5484 - val_accuracy: 0.0703\n",
      "Epoch 2/200\n",
      "27216/27216 [==============================] - 3s 93us/step - loss: 3.3749 - accuracy: 0.0931 - val_loss: 3.2683 - val_accuracy: 0.1057\n",
      "Epoch 3/200\n",
      "27216/27216 [==============================] - 3s 102us/step - loss: 3.1298 - accuracy: 0.1348 - val_loss: 3.0763 - val_accuracy: 0.1399\n",
      "Epoch 4/200\n",
      "27216/27216 [==============================] - 2s 91us/step - loss: 2.9394 - accuracy: 0.1746 - val_loss: 2.9381 - val_accuracy: 0.1631\n",
      "Epoch 5/200\n",
      "27216/27216 [==============================] - 2s 88us/step - loss: 2.7847 - accuracy: 0.2073 - val_loss: 2.8088 - val_accuracy: 0.1883\n",
      "Epoch 6/200\n",
      "27216/27216 [==============================] - 2s 90us/step - loss: 2.6464 - accuracy: 0.2352 - val_loss: 2.6700 - val_accuracy: 0.2311\n",
      "Epoch 7/200\n",
      "27216/27216 [==============================] - 3s 110us/step - loss: 2.5210 - accuracy: 0.2673 - val_loss: 2.5708 - val_accuracy: 0.2405\n",
      "Epoch 8/200\n",
      "27216/27216 [==============================] - 2s 87us/step - loss: 2.4074 - accuracy: 0.2988 - val_loss: 2.4809 - val_accuracy: 0.2630\n",
      "Epoch 9/200\n",
      "27216/27216 [==============================] - 3s 112us/step - loss: 2.3073 - accuracy: 0.3188 - val_loss: 2.4017 - val_accuracy: 0.2761\n",
      "Epoch 10/200\n",
      "27216/27216 [==============================] - 3s 94us/step - loss: 2.2123 - accuracy: 0.3443 - val_loss: 2.2911 - val_accuracy: 0.3134\n",
      "Epoch 11/200\n",
      "27216/27216 [==============================] - 2s 88us/step - loss: 2.1287 - accuracy: 0.3655 - val_loss: 2.2347 - val_accuracy: 0.3255\n",
      "Epoch 12/200\n",
      "27216/27216 [==============================] - 3s 92us/step - loss: 2.0469 - accuracy: 0.3897 - val_loss: 2.1477 - val_accuracy: 0.3447\n",
      "Epoch 13/200\n",
      "27216/27216 [==============================] - 2s 87us/step - loss: 1.9739 - accuracy: 0.4099 - val_loss: 2.1115 - val_accuracy: 0.3586\n",
      "Epoch 14/200\n",
      "27216/27216 [==============================] - 2s 89us/step - loss: 1.9099 - accuracy: 0.4279 - val_loss: 2.0415 - val_accuracy: 0.3684\n",
      "Epoch 15/200\n",
      "27216/27216 [==============================] - 2s 87us/step - loss: 1.8482 - accuracy: 0.4400 - val_loss: 1.9799 - val_accuracy: 0.3903\n",
      "Epoch 16/200\n",
      "27216/27216 [==============================] - 2s 90us/step - loss: 1.7948 - accuracy: 0.4545 - val_loss: 1.9560 - val_accuracy: 0.3965\n",
      "Epoch 17/200\n",
      "27216/27216 [==============================] - 2s 90us/step - loss: 1.7450 - accuracy: 0.4682 - val_loss: 1.8950 - val_accuracy: 0.4072\n",
      "Epoch 18/200\n",
      "27216/27216 [==============================] - 2s 89us/step - loss: 1.6934 - accuracy: 0.4824 - val_loss: 1.8430 - val_accuracy: 0.4264\n",
      "Epoch 19/200\n",
      "27216/27216 [==============================] - 3s 98us/step - loss: 1.6501 - accuracy: 0.4968 - val_loss: 1.8195 - val_accuracy: 0.4279\n",
      "Epoch 20/200\n",
      "27216/27216 [==============================] - 3s 105us/step - loss: 1.6102 - accuracy: 0.5090 - val_loss: 1.7901 - val_accuracy: 0.4343\n",
      "Epoch 21/200\n",
      "27216/27216 [==============================] - 3s 113us/step - loss: 1.5694 - accuracy: 0.5173 - val_loss: 1.7526 - val_accuracy: 0.4501\n",
      "Epoch 22/200\n",
      "27216/27216 [==============================] - 3s 109us/step - loss: 1.5322 - accuracy: 0.5289 - val_loss: 1.7228 - val_accuracy: 0.4497\n",
      "Epoch 23/200\n",
      "27216/27216 [==============================] - 3s 100us/step - loss: 1.4953 - accuracy: 0.5366 - val_loss: 1.6986 - val_accuracy: 0.4608\n",
      "Epoch 24/200\n",
      "27216/27216 [==============================] - 3s 93us/step - loss: 1.4636 - accuracy: 0.5444 - val_loss: 1.6732 - val_accuracy: 0.4669\n",
      "Epoch 25/200\n",
      "27216/27216 [==============================] - 3s 96us/step - loss: 1.4331 - accuracy: 0.5535 - val_loss: 1.6196 - val_accuracy: 0.4785\n",
      "Epoch 26/200\n",
      "27216/27216 [==============================] - 2s 89us/step - loss: 1.4087 - accuracy: 0.5606 - val_loss: 1.6182 - val_accuracy: 0.4816\n",
      "Epoch 27/200\n",
      "27216/27216 [==============================] - 3s 98us/step - loss: 1.3793 - accuracy: 0.5660 - val_loss: 1.5910 - val_accuracy: 0.4869\n",
      "Epoch 28/200\n",
      "27216/27216 [==============================] - 3s 95us/step - loss: 1.3536 - accuracy: 0.5755 - val_loss: 1.5505 - val_accuracy: 0.5007\n",
      "Epoch 29/200\n",
      "27216/27216 [==============================] - 3s 97us/step - loss: 1.3273 - accuracy: 0.5822 - val_loss: 1.5329 - val_accuracy: 0.5011\n",
      "Epoch 30/200\n",
      "27216/27216 [==============================] - 2s 92us/step - loss: 1.3046 - accuracy: 0.5905 - val_loss: 1.5445 - val_accuracy: 0.5006\n",
      "Epoch 31/200\n",
      "27216/27216 [==============================] - 3s 98us/step - loss: 1.2799 - accuracy: 0.5959 - val_loss: 1.5076 - val_accuracy: 0.5099\n",
      "Epoch 32/200\n",
      "27216/27216 [==============================] - 3s 98us/step - loss: 1.2575 - accuracy: 0.6007 - val_loss: 1.4968 - val_accuracy: 0.5101\n",
      "Epoch 33/200\n",
      "27216/27216 [==============================] - 3s 96us/step - loss: 1.2410 - accuracy: 0.6047 - val_loss: 1.4837 - val_accuracy: 0.5188\n",
      "Epoch 34/200\n",
      "27216/27216 [==============================] - 3s 93us/step - loss: 1.2184 - accuracy: 0.6129 - val_loss: 1.4567 - val_accuracy: 0.5249\n",
      "Epoch 35/200\n",
      "27216/27216 [==============================] - 3s 97us/step - loss: 1.1959 - accuracy: 0.6189 - val_loss: 1.4447 - val_accuracy: 0.5247\n",
      "Epoch 36/200\n",
      "27216/27216 [==============================] - 3s 94us/step - loss: 1.1792 - accuracy: 0.6210 - val_loss: 1.4182 - val_accuracy: 0.5316\n",
      "Epoch 37/200\n",
      "27216/27216 [==============================] - 3s 99us/step - loss: 1.1635 - accuracy: 0.6290 - val_loss: 1.4224 - val_accuracy: 0.5335\n",
      "Epoch 38/200\n",
      "27216/27216 [==============================] - 3s 93us/step - loss: 1.1458 - accuracy: 0.6329 - val_loss: 1.4110 - val_accuracy: 0.5402\n",
      "Epoch 39/200\n",
      "27216/27216 [==============================] - 3s 94us/step - loss: 1.1264 - accuracy: 0.6383 - val_loss: 1.3937 - val_accuracy: 0.5391\n",
      "Epoch 40/200\n",
      "27216/27216 [==============================] - 3s 101us/step - loss: 1.1099 - accuracy: 0.6426 - val_loss: 1.3833 - val_accuracy: 0.5422\n",
      "Epoch 41/200\n",
      "27216/27216 [==============================] - 3s 94us/step - loss: 1.0968 - accuracy: 0.6483 - val_loss: 1.3768 - val_accuracy: 0.5441\n",
      "Epoch 42/200\n",
      "27216/27216 [==============================] - 3s 93us/step - loss: 1.0831 - accuracy: 0.6504 - val_loss: 1.3553 - val_accuracy: 0.5478\n",
      "Epoch 43/200\n",
      "27216/27216 [==============================] - 3s 94us/step - loss: 1.0665 - accuracy: 0.6574 - val_loss: 1.3468 - val_accuracy: 0.5504\n",
      "Epoch 44/200\n",
      "27216/27216 [==============================] - 3s 96us/step - loss: 1.0575 - accuracy: 0.6612 - val_loss: 1.3356 - val_accuracy: 0.5561\n",
      "Epoch 45/200\n",
      "27216/27216 [==============================] - 3s 94us/step - loss: 1.0379 - accuracy: 0.6648 - val_loss: 1.3342 - val_accuracy: 0.5496\n",
      "Epoch 46/200\n",
      "27216/27216 [==============================] - 3s 93us/step - loss: 1.0257 - accuracy: 0.6674 - val_loss: 1.3183 - val_accuracy: 0.5592\n",
      "Epoch 47/200\n",
      "27216/27216 [==============================] - 3s 95us/step - loss: 1.0114 - accuracy: 0.6763 - val_loss: 1.3123 - val_accuracy: 0.5634\n",
      "Epoch 48/200\n",
      "27216/27216 [==============================] - 3s 95us/step - loss: 1.0013 - accuracy: 0.6757 - val_loss: 1.3154 - val_accuracy: 0.5672\n",
      "Epoch 49/200\n",
      "27216/27216 [==============================] - 3s 101us/step - loss: 0.9856 - accuracy: 0.6796 - val_loss: 1.3038 - val_accuracy: 0.5638\n",
      "Epoch 50/200\n",
      "27216/27216 [==============================] - 3s 93us/step - loss: 0.9769 - accuracy: 0.6801 - val_loss: 1.2791 - val_accuracy: 0.5765\n",
      "Epoch 51/200\n",
      "27216/27216 [==============================] - 3s 97us/step - loss: 0.9642 - accuracy: 0.6834 - val_loss: 1.3007 - val_accuracy: 0.5662\n",
      "Epoch 52/200\n",
      "27216/27216 [==============================] - 3s 96us/step - loss: 0.9533 - accuracy: 0.6901 - val_loss: 1.2839 - val_accuracy: 0.5761\n",
      "Epoch 53/200\n",
      "27216/27216 [==============================] - 3s 102us/step - loss: 0.9462 - accuracy: 0.6928 - val_loss: 1.2609 - val_accuracy: 0.5795\n",
      "Epoch 54/200\n",
      "27216/27216 [==============================] - 3s 96us/step - loss: 0.9331 - accuracy: 0.6981 - val_loss: 1.2633 - val_accuracy: 0.5794\n",
      "Epoch 55/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27216/27216 [==============================] - 3s 95us/step - loss: 0.9254 - accuracy: 0.6993 - val_loss: 1.2355 - val_accuracy: 0.5830\n",
      "Epoch 56/200\n",
      "27216/27216 [==============================] - 3s 99us/step - loss: 0.9156 - accuracy: 0.7016 - val_loss: 1.2286 - val_accuracy: 0.5870\n",
      "Epoch 57/200\n",
      "27216/27216 [==============================] - 3s 94us/step - loss: 0.9049 - accuracy: 0.7043 - val_loss: 1.2352 - val_accuracy: 0.5881\n",
      "Epoch 58/200\n",
      "27216/27216 [==============================] - 3s 99us/step - loss: 0.8936 - accuracy: 0.7088 - val_loss: 1.2361 - val_accuracy: 0.5872\n",
      "Epoch 59/200\n",
      "27216/27216 [==============================] - 3s 96us/step - loss: 0.8835 - accuracy: 0.7118 - val_loss: 1.2279 - val_accuracy: 0.5874\n",
      "Epoch 60/200\n",
      "27216/27216 [==============================] - 3s 94us/step - loss: 0.8726 - accuracy: 0.7128 - val_loss: 1.2072 - val_accuracy: 0.5953\n",
      "Epoch 61/200\n",
      "27216/27216 [==============================] - 3s 95us/step - loss: 0.8672 - accuracy: 0.7178 - val_loss: 1.2254 - val_accuracy: 0.5829\n",
      "Epoch 62/200\n",
      "27216/27216 [==============================] - 3s 94us/step - loss: 0.8593 - accuracy: 0.7168 - val_loss: 1.2038 - val_accuracy: 0.5975\n",
      "Epoch 63/200\n",
      "27216/27216 [==============================] - 3s 95us/step - loss: 0.8473 - accuracy: 0.7231 - val_loss: 1.1989 - val_accuracy: 0.5940\n",
      "Epoch 64/200\n",
      "27216/27216 [==============================] - 3s 92us/step - loss: 0.8408 - accuracy: 0.7238 - val_loss: 1.1835 - val_accuracy: 0.5947\n",
      "Epoch 65/200\n",
      "27216/27216 [==============================] - 3s 96us/step - loss: 0.8334 - accuracy: 0.7263 - val_loss: 1.1848 - val_accuracy: 0.6015\n",
      "Epoch 66/200\n",
      "27216/27216 [==============================] - 3s 95us/step - loss: 0.8292 - accuracy: 0.7292 - val_loss: 1.1838 - val_accuracy: 0.6062\n",
      "Epoch 67/200\n",
      "27216/27216 [==============================] - 3s 99us/step - loss: 0.8194 - accuracy: 0.7303 - val_loss: 1.1646 - val_accuracy: 0.6061\n",
      "Epoch 68/200\n",
      "27216/27216 [==============================] - 3s 97us/step - loss: 0.8075 - accuracy: 0.7344 - val_loss: 1.1703 - val_accuracy: 0.6057\n",
      "Epoch 69/200\n",
      "27216/27216 [==============================] - 3s 97us/step - loss: 0.8021 - accuracy: 0.7366 - val_loss: 1.1668 - val_accuracy: 0.6055\n",
      "Epoch 70/200\n",
      "27216/27216 [==============================] - 3s 95us/step - loss: 0.7941 - accuracy: 0.7397 - val_loss: 1.1603 - val_accuracy: 0.6061\n",
      "Epoch 71/200\n",
      "27216/27216 [==============================] - 3s 98us/step - loss: 0.7871 - accuracy: 0.7387 - val_loss: 1.1544 - val_accuracy: 0.6109\n",
      "Epoch 72/200\n",
      "27216/27216 [==============================] - 3s 99us/step - loss: 0.7820 - accuracy: 0.7430 - val_loss: 1.1517 - val_accuracy: 0.6134\n",
      "Epoch 73/200\n",
      "27216/27216 [==============================] - 3s 94us/step - loss: 0.7726 - accuracy: 0.7456 - val_loss: 1.1538 - val_accuracy: 0.6161\n",
      "Epoch 74/200\n",
      "27216/27216 [==============================] - 3s 97us/step - loss: 0.7710 - accuracy: 0.7477 - val_loss: 1.1352 - val_accuracy: 0.6155\n",
      "Epoch 75/200\n",
      "27216/27216 [==============================] - 3s 97us/step - loss: 0.7608 - accuracy: 0.7503 - val_loss: 1.1316 - val_accuracy: 0.6114\n",
      "Epoch 76/200\n",
      "27216/27216 [==============================] - 3s 97us/step - loss: 0.7552 - accuracy: 0.7538 - val_loss: 1.1657 - val_accuracy: 0.6049\n",
      "Epoch 77/200\n",
      "27216/27216 [==============================] - 3s 95us/step - loss: 0.7470 - accuracy: 0.7529 - val_loss: 1.1395 - val_accuracy: 0.6160\n",
      "Epoch 78/200\n",
      "27216/27216 [==============================] - 3s 96us/step - loss: 0.7398 - accuracy: 0.7564 - val_loss: 1.1522 - val_accuracy: 0.6135\n",
      "Epoch 79/200\n",
      "27216/27216 [==============================] - 3s 99us/step - loss: 0.7351 - accuracy: 0.7579 - val_loss: 1.1297 - val_accuracy: 0.6173\n",
      "Epoch 80/200\n",
      "27216/27216 [==============================] - 3s 97us/step - loss: 0.7317 - accuracy: 0.7579 - val_loss: 1.1275 - val_accuracy: 0.6122\n",
      "Epoch 81/200\n",
      "27216/27216 [==============================] - 9s 332us/step - loss: 0.7233 - accuracy: 0.7598 - val_loss: 1.1146 - val_accuracy: 0.6271\n",
      "Epoch 82/200\n",
      "27216/27216 [==============================] - 3s 124us/step - loss: 0.7146 - accuracy: 0.7651 - val_loss: 1.1222 - val_accuracy: 0.6199\n",
      "Epoch 83/200\n",
      "27216/27216 [==============================] - 3s 99us/step - loss: 0.7122 - accuracy: 0.7650 - val_loss: 1.1113 - val_accuracy: 0.6249\n",
      "Epoch 84/200\n",
      "27216/27216 [==============================] - 3s 96us/step - loss: 0.7037 - accuracy: 0.7671 - val_loss: 1.1212 - val_accuracy: 0.6274\n",
      "Epoch 85/200\n",
      "27216/27216 [==============================] - 3s 97us/step - loss: 0.7017 - accuracy: 0.7686 - val_loss: 1.1327 - val_accuracy: 0.6199\n",
      "Epoch 86/200\n",
      "27216/27216 [==============================] - 3s 120us/step - loss: 0.6903 - accuracy: 0.7723 - val_loss: 1.1146 - val_accuracy: 0.6215\n",
      "Epoch 87/200\n",
      "27216/27216 [==============================] - 3s 99us/step - loss: 0.6844 - accuracy: 0.7726 - val_loss: 1.0808 - val_accuracy: 0.6337\n",
      "Epoch 88/200\n",
      "27216/27216 [==============================] - 3s 98us/step - loss: 0.6818 - accuracy: 0.7736 - val_loss: 1.0920 - val_accuracy: 0.6322\n",
      "Epoch 89/200\n",
      "27216/27216 [==============================] - 3s 97us/step - loss: 0.6745 - accuracy: 0.7778 - val_loss: 1.1098 - val_accuracy: 0.6289\n",
      "Epoch 90/200\n",
      "27216/27216 [==============================] - 3s 94us/step - loss: 0.6721 - accuracy: 0.7788 - val_loss: 1.1240 - val_accuracy: 0.6254\n",
      "Epoch 91/200\n",
      "27216/27216 [==============================] - 2s 91us/step - loss: 0.6677 - accuracy: 0.7781 - val_loss: 1.1210 - val_accuracy: 0.6264\n",
      "Epoch 92/200\n",
      "27216/27216 [==============================] - 3s 97us/step - loss: 0.6623 - accuracy: 0.7813 - val_loss: 1.0872 - val_accuracy: 0.6343\n",
      "Epoch 93/200\n",
      "27216/27216 [==============================] - 2s 88us/step - loss: 0.6563 - accuracy: 0.7812 - val_loss: 1.1091 - val_accuracy: 0.6321\n",
      "Epoch 94/200\n",
      "27216/27216 [==============================] - 2s 90us/step - loss: 0.6522 - accuracy: 0.7844 - val_loss: 1.0850 - val_accuracy: 0.6385\n",
      "Epoch 95/200\n",
      "27216/27216 [==============================] - 2s 88us/step - loss: 0.6464 - accuracy: 0.7850 - val_loss: 1.0935 - val_accuracy: 0.6307\n",
      "Epoch 96/200\n",
      "27216/27216 [==============================] - 2s 85us/step - loss: 0.6412 - accuracy: 0.7864 - val_loss: 1.0858 - val_accuracy: 0.6391\n",
      "Epoch 97/200\n",
      "27216/27216 [==============================] - 3s 100us/step - loss: 0.6403 - accuracy: 0.7878 - val_loss: 1.0900 - val_accuracy: 0.6349\n",
      "Epoch 98/200\n",
      "27216/27216 [==============================] - 3s 93us/step - loss: 0.6322 - accuracy: 0.7897 - val_loss: 1.0938 - val_accuracy: 0.6333\n",
      "Epoch 99/200\n",
      "27216/27216 [==============================] - 2s 91us/step - loss: 0.6247 - accuracy: 0.7941 - val_loss: 1.0703 - val_accuracy: 0.6383\n",
      "Epoch 100/200\n",
      "27216/27216 [==============================] - 3s 93us/step - loss: 0.6248 - accuracy: 0.7932 - val_loss: 1.1125 - val_accuracy: 0.6295\n",
      "Epoch 101/200\n",
      "27216/27216 [==============================] - 3s 98us/step - loss: 0.6219 - accuracy: 0.7930 - val_loss: 1.1261 - val_accuracy: 0.6292\n",
      "Epoch 102/200\n",
      "27216/27216 [==============================] - 3s 99us/step - loss: 0.6160 - accuracy: 0.7955 - val_loss: 1.0972 - val_accuracy: 0.6375\n",
      "Epoch 103/200\n",
      "27216/27216 [==============================] - 12s 458us/step - loss: 0.6113 - accuracy: 0.7972 - val_loss: 1.0672 - val_accuracy: 0.6405s - loss: - ETA: 1s - loss: 0.6125 - accuracy:  - ETA: 1s - loss: 0 - ETA: 1s - loss: 0.6135 - ac -\n",
      "Epoch 104/200\n",
      "27216/27216 [==============================] - 6s 208us/step - loss: 0.6023 - accuracy: 0.8002 - val_loss: 1.1085 - val_accuracy: 0.6346\n",
      "Epoch 105/200\n",
      "27216/27216 [==============================] - 5s 175us/step - loss: 0.6056 - accuracy: 0.7979 - val_loss: 1.0561 - val_accuracy: 0.6477\n",
      "Epoch 106/200\n",
      "27216/27216 [==============================] - 3s 128us/step - loss: 0.6011 - accuracy: 0.8002 - val_loss: 1.0986 - val_accuracy: 0.6352\n",
      "Epoch 107/200\n",
      "27216/27216 [==============================] - 3s 120us/step - loss: 0.5970 - accuracy: 0.8002 - val_loss: 1.0735 - val_accuracy: 0.6473\n",
      "Epoch 108/200\n",
      "27216/27216 [==============================] - 3s 120us/step - loss: 0.5892 - accuracy: 0.8038 - val_loss: 1.0755 - val_accuracy: 0.6396\n",
      "Epoch 109/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27216/27216 [==============================] - 3s 122us/step - loss: 0.5870 - accuracy: 0.8046 - val_loss: 1.0714 - val_accuracy: 0.6438\n",
      "Epoch 110/200\n",
      "27216/27216 [==============================] - 3s 111us/step - loss: 0.5794 - accuracy: 0.8062 - val_loss: 1.0661 - val_accuracy: 0.6445\n",
      "Epoch 111/200\n",
      "27216/27216 [==============================] - 3s 128us/step - loss: 0.5778 - accuracy: 0.8072 - val_loss: 1.0777 - val_accuracy: 0.6407\n",
      "Epoch 112/200\n",
      "27216/27216 [==============================] - 3s 115us/step - loss: 0.5749 - accuracy: 0.8090 - val_loss: 1.0638 - val_accuracy: 0.6461\n",
      "Epoch 113/200\n",
      "27216/27216 [==============================] - 4s 138us/step - loss: 0.5722 - accuracy: 0.8064 - val_loss: 1.0661 - val_accuracy: 0.6494\n",
      "Epoch 114/200\n",
      "27216/27216 [==============================] - 3s 128us/step - loss: 0.5651 - accuracy: 0.8109 - val_loss: 1.0527 - val_accuracy: 0.6519\n",
      "Epoch 115/200\n",
      "27216/27216 [==============================] - 3s 109us/step - loss: 0.5702 - accuracy: 0.8097 - val_loss: 1.0831 - val_accuracy: 0.6433\n",
      "Epoch 116/200\n",
      "27216/27216 [==============================] - 4s 132us/step - loss: 0.5587 - accuracy: 0.8146 - val_loss: 1.0606 - val_accuracy: 0.6513\n",
      "Epoch 117/200\n",
      "27216/27216 [==============================] - 3s 101us/step - loss: 0.5579 - accuracy: 0.8130 - val_loss: 1.0423 - val_accuracy: 0.6553\n",
      "Epoch 118/200\n",
      "27216/27216 [==============================] - 3s 97us/step - loss: 0.5507 - accuracy: 0.8162 - val_loss: 1.0631 - val_accuracy: 0.6514\n",
      "Epoch 119/200\n",
      "27216/27216 [==============================] - 3s 101us/step - loss: 0.5477 - accuracy: 0.8153 - val_loss: 1.0682 - val_accuracy: 0.6458\n",
      "Epoch 120/200\n",
      "27216/27216 [==============================] - 3s 117us/step - loss: 0.5471 - accuracy: 0.8180 - val_loss: 1.0478 - val_accuracy: 0.6523\n",
      "Epoch 121/200\n",
      "27216/27216 [==============================] - 3s 108us/step - loss: 0.5428 - accuracy: 0.8196 - val_loss: 1.0940 - val_accuracy: 0.6398\n",
      "Epoch 122/200\n",
      "27216/27216 [==============================] - 3s 103us/step - loss: 0.5367 - accuracy: 0.8201 - val_loss: 1.0950 - val_accuracy: 0.6396\n",
      "Epoch 123/200\n",
      "27216/27216 [==============================] - 3s 96us/step - loss: 0.5366 - accuracy: 0.8215 - val_loss: 1.0537 - val_accuracy: 0.6540\n",
      "Epoch 124/200\n",
      "27216/27216 [==============================] - 3s 104us/step - loss: 0.5330 - accuracy: 0.8228 - val_loss: 1.0750 - val_accuracy: 0.6470\n",
      "Epoch 125/200\n",
      "27216/27216 [==============================] - 3s 101us/step - loss: 0.5298 - accuracy: 0.8233 - val_loss: 1.0725 - val_accuracy: 0.6517\n",
      "Epoch 126/200\n",
      "27216/27216 [==============================] - 3s 106us/step - loss: 0.5293 - accuracy: 0.8214 - val_loss: 1.0549 - val_accuracy: 0.6511\n",
      "Epoch 127/200\n",
      "27216/27216 [==============================] - 5s 185us/step - loss: 0.5234 - accuracy: 0.8252 - val_loss: 1.0548 - val_accuracy: 0.6493\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2b1884fe5c0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs=200\n",
    "\n",
    "model = get_model(train_content.shape[1])\n",
    "callbacks = [EarlyStopping('val_accuracy', patience=10),]\n",
    "model.fit(train_content, onehot_classes, epochs=n_epochs, validation_split=0.3, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27216 samples, validate on 11664 samples\n",
      "Epoch 1/200\n",
      "27216/27216 [==============================] - 10s 355us/step - loss: 0.3115 - accuracy: 0.9723 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 2/200\n",
      "27216/27216 [==============================] - 5s 190us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 3/200\n",
      "27216/27216 [==============================] - 4s 141us/step - loss: 7.3251e-04 - accuracy: 1.0000 - val_loss: 4.5946e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/200\n",
      "27216/27216 [==============================] - 3s 127us/step - loss: 3.2271e-04 - accuracy: 1.0000 - val_loss: 2.2385e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/200\n",
      "27216/27216 [==============================] - 3s 120us/step - loss: 1.6533e-04 - accuracy: 1.0000 - val_loss: 1.2060e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/200\n",
      "27216/27216 [==============================] - 3s 119us/step - loss: 9.1532e-05 - accuracy: 1.0000 - val_loss: 6.8676e-05 - val_accuracy: 1.0000\n",
      "Epoch 7/200\n",
      "27216/27216 [==============================] - 3s 107us/step - loss: 5.2979e-05 - accuracy: 1.0000 - val_loss: 4.0457e-05 - val_accuracy: 1.0000\n",
      "Epoch 8/200\n",
      "27216/27216 [==============================] - 3s 107us/step - loss: 3.1506e-05 - accuracy: 1.0000 - val_loss: 2.4218e-05 - val_accuracy: 1.0000\n",
      "Epoch 9/200\n",
      "27216/27216 [==============================] - 3s 123us/step - loss: 1.9034e-05 - accuracy: 1.0000 - val_loss: 1.4775e-05 - val_accuracy: 1.0000\n",
      "Epoch 10/200\n",
      "27216/27216 [==============================] - 3s 108us/step - loss: 1.1630e-05 - accuracy: 1.0000 - val_loss: 9.0491e-06 - val_accuracy: 1.0000\n",
      "Epoch 11/200\n",
      "27216/27216 [==============================] - 3s 106us/step - loss: 7.1585e-06 - accuracy: 1.0000 - val_loss: 5.6051e-06 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2b1895cadd8>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs=200\n",
    "\n",
    "model = get_model(class_code.shape[1])\n",
    "callbacks = [EarlyStopping('val_accuracy', patience=10),]\n",
    "model.fit(class_code, onehot_classes, epochs=n_epochs, validation_split=0.3, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
