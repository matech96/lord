{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"DISENTANGLEMENT_LIB_DATA\"] = r\"C:\\Users\\gango\\Projects\\lord\\data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# coding=utf-8\n",
    "# Copyright 2018 The DisentanglementLib Authors.  All rights reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "\"\"\"Example script how to get started with research using disentanglement_lib.\n",
    "\n",
    "To run the example, please change the working directory to the containing folder\n",
    "and run:\n",
    ">> python example.py\n",
    "\n",
    "In this example, we show how to use disentanglement_lib to:\n",
    "1. Train a standard VAE (already implemented in disentanglement_lib).\n",
    "2. Train a custom VAE model.\n",
    "3. Extract the mean representations for both of these models.\n",
    "4. Compute the Mutual Information Gap (already implemented) for both models.\n",
    "5. Compute a custom disentanglement metric for both models.\n",
    "6. Aggregate the results.\n",
    "7. Print out the final Pandas data frame with the results.\n",
    "\"\"\"\n",
    "\n",
    "# We group all the imports at the top.\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import os\n",
    "from disentanglement_lib.evaluation import evaluate\n",
    "from disentanglement_lib.evaluation.metrics import utils\n",
    "from disentanglement_lib.methods.unsupervised import train\n",
    "from disentanglement_lib.methods.unsupervised import vae\n",
    "from disentanglement_lib.postprocessing import postprocess\n",
    "from disentanglement_lib.utils import aggregate_results\n",
    "import tensorflow as tf\n",
    "import gin.tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. Settings\n",
    "# ------------------------------------------------------------------------------\n",
    "# By default, we save all the results in subdirectories of the following path.\n",
    "base_path = \"example_output\"\n",
    "\n",
    "# By default, we do not overwrite output directories. Set this to True, if you\n",
    "# want to overwrite (in particular, if you rerun this script several times).\n",
    "overwrite = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\disentanglement_lib\\methods\\unsupervised\\train.py:89: The name tf.gfile.IsDirectory is deprecated. Please use tf.io.gfile.isdir instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\disentanglement_lib\\data\\ground_truth\\dsprites.py:59: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:Estimator's model_fn (<bound method BaseVAE.model_fn of <disentanglement_lib.methods.unsupervised.vae.BetaVAE object at 0x0000025C5F95A978>>) includes params argument, but params are not passed to Estimator.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'example_output\\\\vae\\\\model\\\\tf_checkpoint', '_tf_random_seed': 0, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 1, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000025C61B43390>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=500, num_shards=None, num_cores_per_replica=None, per_host_input_for_training=2, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2), '_cluster': None}\n",
      "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
      "WARNING:tensorflow:eval_on_tpu ignored because use_tpu is False.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "high is out of bounds for int32\n  In call to configurable 'model' (<function train at 0x0000025C5FBDA620>)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-7e36a030615b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# training we need to provide a gin config. For a standard VAE, you may have a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# look at model.gin on how to do this.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_with_gin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_vae\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"model\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"model.gin\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;31m# After this command, you should have a `vae` subfolder with a model that was\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# trained for a few steps (in reality, you will want to train many more steps).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\disentanglement_lib\\methods\\unsupervised\\train.py\u001b[0m in \u001b[0;36mtrain_with_gin\u001b[1;34m(model_dir, overwrite, gin_config_files, gin_bindings)\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mgin_bindings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[0mgin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_config_files_and_bindings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgin_config_files\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgin_bindings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m   \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m   \u001b[0mgin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclear_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gin\\config.py\u001b[0m in \u001b[0;36mgin_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1076\u001b[0m       \u001b[0mscope_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\" in scope '{}'\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscope_str\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mscope_str\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1077\u001b[0m       \u001b[0merr_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merr_str\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn_or_cls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscope_info\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1078\u001b[1;33m       \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maugment_exception_message_and_reraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merr_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1079\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1080\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mgin_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gin\\utils.py\u001b[0m in \u001b[0;36maugment_exception_message_and_reraise\u001b[1;34m(exception, message)\u001b[0m\n\u001b[0;32m     47\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPY3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[0mExceptionProxy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__qualname__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexception\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__qualname__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproxy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexception\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproxy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gin\\config.py\u001b[0m in \u001b[0;36mgin_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1053\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1054\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1055\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnew_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mnew_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1056\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1057\u001b[0m       \u001b[0merr_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\disentanglement_lib\\methods\\unsupervised\\train.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    120\u001b[0m   \u001b[1;31m# Do the actual training.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m   tpu_estimator.train(\n\u001b[1;32m--> 122\u001b[1;33m       \u001b[0minput_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_make_input_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    123\u001b[0m       steps=training_steps)\n\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.randint\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_bounded_integers.pyx\u001b[0m in \u001b[0;36mnumpy.random._bounded_integers._rand_int32\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: high is out of bounds for int32\n  In call to configurable 'model' (<function train at 0x0000025C5FBDA620>)"
     ]
    }
   ],
   "source": [
    "# 1. Train a standard VAE (already implemented in disentanglement_lib).\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "# We save the results in a `vae` subfolder.\n",
    "path_vae = os.path.join(base_path, \"vae\")\n",
    "\n",
    "# The main training protocol of disentanglement_lib is defined in the\n",
    "# disentanglement_lib.methods.unsupervised.train module. To configure\n",
    "# training we need to provide a gin config. For a standard VAE, you may have a\n",
    "# look at model.gin on how to do this.\n",
    "train.train_with_gin(os.path.join(path_vae, \"model\"), overwrite, [\"model.gin\"])\n",
    "# After this command, you should have a `vae` subfolder with a model that was\n",
    "# trained for a few steps (in reality, you will want to train many more steps)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Train a custom VAE model.\n",
    "# ------------------------------------------------------------------------------\n",
    "# To train a custom model, we have to provide an implementation of the class\n",
    "# GaussianEncoderModel in the\n",
    "# disentanglement_lib.methods.unsupervised.gaussian_encoder_model module.\n",
    "# For simplicty, we will subclass the BaseVAE class in\n",
    "# disentanglement_lib.methods.unsupervised.vae which will train a VAE style\n",
    "# model where the loss is given by a reconstruction loss (configured via gin)\n",
    "# plus a custom regularizer (needs to be implemented.)\n",
    "@gin.configurable(\"BottleneckVAE\")  # This will allow us to reference the model.\n",
    "class BottleneckVAE(vae.BaseVAE):\n",
    "  \"\"\"BottleneckVAE.\n",
    "\n",
    "  The loss of this VAE-style model is given by:\n",
    "    loss = reconstruction loss + gamma * |KL(app. posterior | prior) - target|\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, gamma=gin.REQUIRED, target=gin.REQUIRED):\n",
    "    self.gamma = gamma\n",
    "    self.target = target\n",
    "\n",
    "  def regularizer(self, kl_loss, z_mean, z_logvar, z_sampled):\n",
    "    # This is how we customize BaseVAE. To learn more, have a look at the\n",
    "    # different models in vae.py.\n",
    "    del z_mean, z_logvar, z_sampled\n",
    "    return self.gamma * tf.math.abs(kl_loss - self.target)\n",
    "\n",
    "\n",
    "# We use the same training protocol that we defined in model.gin but we use gin\n",
    "# bindings to train our custom VAE instead of the ordinary VAE.\n",
    "gin_bindings = [\n",
    "    \"model.model = @BottleneckVAE()\",\n",
    "    \"BottleneckVAE.gamma = 4\",\n",
    "    \"BottleneckVAE.target = 10.\"\n",
    "]\n",
    "# Call training module to train the custom model.\n",
    "path_custom_vae = os.path.join(base_path, \"BottleneckVAE\")\n",
    "train.train_with_gin(\n",
    "    os.path.join(path_custom_vae, \"model\"), overwrite, [\"model.gin\"],\n",
    "    gin_bindings)\n",
    "# As before, after this command, you should have a `BottleneckVAE` subfolder\n",
    "# with a model that was trained for a few steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Extract the mean representation for both of these models.\n",
    "# ------------------------------------------------------------------------------\n",
    "# To compute disentanglement metrics, we require a representation function that\n",
    "# takes as input an image and that outputs a vector with the representation.\n",
    "# We extract the mean of the encoder from both models using the following code.\n",
    "for path in [path_vae, path_custom_vae]:\n",
    "  representation_path = os.path.join(path, \"representation\")\n",
    "  model_path = os.path.join(path, \"model\")\n",
    "  postprocess_gin = [\"postprocess.gin\"]  # This contains the settings.\n",
    "  # postprocess.postprocess_with_gin defines the standard extraction protocol.\n",
    "  postprocess.postprocess_with_gin(model_path, representation_path, overwrite,\n",
    "                                   postprocess_gin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Compute the Mutual Information Gap (already implemented) for both models.\n",
    "# ------------------------------------------------------------------------------\n",
    "# The main evaluation protocol of disentanglement_lib is defined in the\n",
    "# disentanglement_lib.evaluation.evaluate module. Again, we have to provide a\n",
    "# gin configuration. We could define a .gin config file; however, in this case\n",
    "# we show how all the configuration settings can be set using gin bindings.\n",
    "# We use the Mutual Information Gap (with a low number of samples to make it\n",
    "# faster). To learn more, have a look at the different scores in\n",
    "# disentanglement_lib.evaluation.evaluate.metrics and the predefined .gin\n",
    "# configuration files in\n",
    "# disentanglement_lib/config/unsupervised_study_v1/metrics_configs/(...).\n",
    "gin_bindings = [\n",
    "    \"evaluation.evaluation_fn = @mig\",\n",
    "    \"dataset.name='auto'\",\n",
    "    \"evaluation.random_seed = 0\",\n",
    "    \"mig.num_train=1000\",\n",
    "    \"discretizer.discretizer_fn = @histogram_discretizer\",\n",
    "    \"discretizer.num_bins = 20\"\n",
    "]\n",
    "for path in [path_vae, path_custom_vae]:\n",
    "  result_path = os.path.join(path, \"metrics\", \"mig\")\n",
    "  representation_path = os.path.join(path, \"representation\")\n",
    "  evaluate.evaluate_with_gin(\n",
    "      representation_path, result_path, overwrite, gin_bindings=gin_bindings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Compute a custom disentanglement metric for both models.\n",
    "# ------------------------------------------------------------------------------\n",
    "# The following function implements a dummy metric. Note that all metrics get\n",
    "# ground_truth_data, representation_function, random_state arguments by the\n",
    "# evaluation protocol, while all other arguments have to be configured via gin.\n",
    "@gin.configurable(\n",
    "    \"custom_metric\",\n",
    "    blacklist=[\"ground_truth_data\", \"representation_function\", \"random_state\"])\n",
    "def compute_custom_metric(ground_truth_data,\n",
    "                          representation_function,\n",
    "                          random_state,\n",
    "                          num_train=gin.REQUIRED,\n",
    "                          batch_size=16):\n",
    "  \"\"\"Example of a custom (dummy) metric.\n",
    "\n",
    "  Preimplemented metrics can be found in disentanglement_lib.evaluation.metrics.\n",
    "\n",
    "  Args:\n",
    "    ground_truth_data: GroundTruthData to be sampled from.\n",
    "    representation_function: Function that takes observations as input and\n",
    "      outputs a dim_representation sized representation for each observation.\n",
    "    random_state: Numpy random state used for randomness.\n",
    "    num_train: Number of points used for training.\n",
    "    batch_size: Batch size for sampling.\n",
    "\n",
    "  Returns:\n",
    "    Dict with disentanglement score.\n",
    "  \"\"\"\n",
    "  score_dict = {}\n",
    "\n",
    "  # This is how to obtain the representations of num_train points along with the\n",
    "  # ground-truth factors of variation.\n",
    "  representation, factors_of_variations = utils.generate_batch_factor_code(\n",
    "      ground_truth_data, representation_function, num_train, random_state,\n",
    "      batch_size)\n",
    "  # We could now compute a metric based on representation and\n",
    "  # factors_of_variations. However, for the sake of brevity, we just return 1.\n",
    "  del representation, factors_of_variations\n",
    "  score_dict[\"custom_metric\"] = 1.\n",
    "  return score_dict\n",
    "\n",
    "\n",
    "# To compute the score, we again call the evaluation protocol with a gin\n",
    "# configuration. At this point, note that for all steps, we have to set a\n",
    "# random seed (in this case via `evaluation.random_seed`).\n",
    "gin_bindings = [\n",
    "    \"evaluation.evaluation_fn = @custom_metric\",\n",
    "    \"custom_metric.num_train = 100\", \"evaluation.random_seed = 0\",\n",
    "    \"dataset.name='auto'\"\n",
    "]\n",
    "for path in [path_vae, path_custom_vae]:\n",
    "  result_path = os.path.join(path, \"metrics\", \"custom_metric\")\n",
    "  evaluate.evaluate_with_gin(\n",
    "      representation_path, result_path, overwrite, gin_bindings=gin_bindings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Aggregate the results.\n",
    "# ------------------------------------------------------------------------------\n",
    "# In the previous steps, we saved the scores to several output directories. We\n",
    "# can aggregate all the results using the following command.\n",
    "pattern = os.path.join(base_path,\n",
    "                       \"*/metrics/*/results/aggregate/evaluation.json\")\n",
    "results_path = os.path.join(base_path, \"results.json\")\n",
    "aggregate_results.aggregate_results_to_json(\n",
    "    pattern, results_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Print out the final Pandas data frame with the results.\n",
    "# ------------------------------------------------------------------------------\n",
    "# The aggregated results contains for each computed metric all the configuration\n",
    "# options and all the results captured in the steps along the pipeline. This\n",
    "# should make it easy to analyze the experimental results in an interactive\n",
    "# Python shell. At this point, note that the scores we computed in this example\n",
    "# are not realistic as we only trained the models for a few steps and our custom\n",
    "# metric always returns 1.\n",
    "model_results = aggregate_results.load_aggregated_json_results(results_path)\n",
    "print(model_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
